---
title: "Admision de posgrado: Exploracion y regresion lineal"
output: 
  html_document:
    keep_md: true
---


###Este conjunto de datos fue construido con el propósito de ayudar a los estudiantes en la preselección de universidades con sus perfiles. El resultado previsto les da una idea justa sobre sus posibilidades de admision para una universidad en particular.

__Para este analisis, utilizaremos el dataset descargado desde Kaggle titulado "Graduate Admission 2". Este dataset nos brinde las siguientes columnas:__

*GRE score: El GRE es un examen estandarizado de opción múltiple que a menudo se requiere para la admisión a programas de posgrado y programas de posgrado en negocios (MBA) a nivel mundial.

*TOEFL score: TOEFL (Test of English as a Foreign Language) es una prueba estandarizada de dominio del idioma inglés, específicamente orientada a hablantes no nativos.

*University Rating: Ranking de la universidad donde estudió el estudiante.

*SOP: Fuerza de la declaración de propósito. 

*LOR: Fuerza de carta de recomendación.

*Undergraduate GPA: Promedio de calificaciones de licenciatura.

*Research Experience: Experiencia de investigacion.

*Chance of Admit: Posibilidad de ser admitido/a.

El analisis consisite en 2 partes. La primera sera una visualizacion de la relacion entre las variables mencionadas, y la segunda parte, un modelo predictivo sobre la posibilidad de que el estudiante sea o no admitido al posgrado. 

*source: https://www.kaggle.com/mohansacharya/graduate-admissions*  

#### Cargando el dataset y librerias a utilizar

```{r, results="hide",message=FALSE}

library(ggplot2)
library(dplyr)
library(GGally)
library(faraway)
options(warn = -1)

admissions <- read.csv('Admission_Predict_Ver1.1.csv')

```

```{r}
str(admissions)
```

####Manipulacion leve de algunos datos

```{r}
#No necesitamos una columna con el indice.
admissions <- admissions[-1]

#La variable "Research" es una categoria

admissions$Research <- as.factor(admissions$Research)

#Existen datos nulos o inexistenes?
sapply(admissions,function(x) sum(is.na(x)))

#No hay datos NA

```

#__Parte 1:__

####Comencemos entonces analizando la posibilidad de que existan valores atipicos (outliers) en nuestra data. Se considera outlier aquel dato que se encuentre 1.5 IQR por debajo del primer cuartil (Q1) o por encima del tercer cuartil (Q3).Lo veremos con graficos boxplots para apreciar la visualizacion:

```{r}
summary(admissions)

boxplot(admissions$GRE.Score)#GRE SCORE, 0 outliers detectados
boxplot(admissions$TOEFL.Score)#TEOFL SCORE, 0 outliers detectados
boxplot(admissions$University.Rating)#UNIVERSITY RATING, 0 outliers detectados
boxplot(admissions$SOP)#SOP, 0 outliers detectados
boxplot(admissions$LOR) #LOR, se detectó 1 outlier
boxplot(admissions$CGPA) #GPA, 0 outliers detectados
boxplot(admissions$Chance.of.Admit)#POSIBILIDAD DE ADMISION,Se detectaron 2 outliers
```

####Eliminar outliers, dado a que solamente son el 0.6% de nuestra data total

```{r}
admissions <- admissions %>%
  filter(LOR > 1, Chance.of.Admit > 0.34)
```

####Estudiemos la relacion entre las variables independientes(GRE,TEOFL,UNIVERSITY RANKING,SOP,LOR,CGPA,RESEARCH) y la variable dependiente (Chance of admit).

En este primer grafico veremos un resumen de las relaciones:

```{r}
ggpairs(admissions,progress = FALSE)
```

####Miremos en mejor detalle abajo las relaciones lineales entre las variables continuas con la dependiente:

#####Podemos observar una relacion positiva medianamente fuerte entre las variables contiuas GRE,TOEFL,y CGPA con la variable dependiente Chance of admission (Posibilidad de admision). Con los datos disponibles entonces veemos que mientras mayor sea el GRE SCORE, mayor sera la posibilidad de ser admitido al programa de posgrado, y lo mismo ocurre con TOEFL, y CGPA.

```{r}
plot(admissions$GRE.Score,admissions$Chance.of.Admit) 
plot(admissions$TOEFL.Score,admissions$Chance.of.Admit)
plot(admissions$CGPA,admissions$Chance.of.Admit)
```

####Estudiemos las variables categoricas y su relacion con la variable dependiente. El eje Y siempre siendo la variable dependiente (Posibilidad de admision).

####Vemos que en cada instancia, mientras mayor sea el valor de las variables discretas, mayor la posibilidad de ingreso.

```{r}
#boxplots
plot(as.factor(admissions$University.Rating),admissions$Chance.of.Admit)#UNIVERSITY RATING
plot(as.factor(admissions$SOP),admissions$Chance.of.Admit)#SOP
plot(as.factor(admissions$LOR),admissions$Chance.of.Admit)#LOR
plot(admissions$Research,admissions$Chance.of.Admit)#RESEARCH
```

####Estudiemos la correlacion entre las variables independiente y variable dependiente:

GRE,TOEFL,CGPA Correlacion fuerte entre variable dependiente y entre si mismas.

Correlacion mediana entre UNIVERSITY,SOP, y LOR con variable dependiente.

```{r}
cor(admissions[-7])
```
####Antes de comenzar a armar los modelos, es necesario llevar a la misma escala a los datos, que tomaran un valor entre 0 y 1, manteniendo su peso. 


#### Formula: x - x minimum/x max - x min


```{r, results="hide"}
(admissions$GRE.Score -min(admissions$GRE.Score))/(max(admissions$GRE.Score) - min(admissions$GRE.Score))

normalize <- function(x){
  
  (x - min(x))/(max(x) - min(x))
  
}

normalize(admissions$GRE.Score)


admissions[c(-7,-8)] <- lapply(admissions[c(-7,-8)],function(x) normalize(x)) %>%
  bind_rows()
```

```{r}
head(admissions, n = 10)

```


####Dividamos en 3 partes al dataset. Uno para entrenar el modelo, uno para validar y comparar modelos, y el ultimo para testear la exactitud final del modelo seleccionado.

```{r}

names(admissions) <- c('GRE','TOEFL','UNI','SOP','LOR','CGPA','RESEARCH','ADMIT')

#train/val/test splitting
set.seed(999)
train_index <- sample(1:nrow(admissions),nrow(admissions) * 0.8)

train_set <- admissions[train_index,]

val_index <- sample(1:nrow(train_set),nrow(train_set) * .2)

val_set <- train_set[val_index,]

train_set <- train_set[-val_index,]

test_set <- admissions[-train_index,]
```

#__Parte 2:__

Comparasion entre 2 modelos, el primero lo hare con las variables independientes mas correlacionadas con la variable dependiente(chance of admit)  
El segundo modelo utilizara todas las variables.  
model_1 : variables independientes: GRE,TOEFL,CGPA  
model_2 : variables independientes - todas las variables en el dataset     


#### Modelo 1

Observemos abajo lo siguiente:  
- Las tres variables son estadisticamente significantes.  
Estimadores significantes:    
- Por cada unidad de GRE, la posibilidad de admision se incrementa en 0.10911 unidades.   
- Por cada unidad de TEOFL, la posibilidad de admision se incrementa en 0.09337 unidades.  
- Por cada unidad de CGPA, la posibilidad de admision se incrementa en 0.43329 unidades.  
- *Tengan en cuenta que estas variables estan escaladas, en la cual un aumento de 1 en CGPA , significaria un aumento de 0.43 unidades en la posidibildad de ser admitido, cuyo maximo valor es 1.*  

R2 = 0.7814.   
GRE, TEOFL y CGPA representan ~ 78% de la variabilidad de ADMIT, la variable dependiente.

```{r}

model_1 <- lm(ADMIT ~ GRE + TOEFL + CGPA, data=train_set)

model_1

summary(model_1)

```

####Prueba de multicolinealidad (La multicolinealidad es la relación de dependencia lineal fuerte entre más de dos variables explicativas en una regresión múltiple, su presencia puede causar un modelo ineficaz.)

No hay evidencia de la presencia de multicolinealidad excesiva. 
```{r}

vif(model_1)

```
####RMSE test del modelo 1 en nuestro set de validacion

####RMSE es una medida de uso frecuente de las diferencias entre los valores predichos por un modelo o un estimador y los valores observados. Mientras menos sea el valor del RMSE, mejor habilidad predictiva tiene nuestro modelo.

```{r}


admit <- val_set$ADMIT

val_set$model_1 <- predict(model_1,newdata=val_set)

(rmse_model_1 <- sqrt(mean((admit - val_set$model_1)^2)))
#RMSE = 0.06575011
#R2 = 0.7814


```


####Grafico modelo 1
```{r}
ggplot(val_set,aes(x = model_1, y = ADMIT))+
  geom_point()+
  geom_smooth(method = 'lm',se = F)
```

####Modelo 2, utilizando todas las variables

Observaciones:  
-UNI, Y SOP no son significantes.  
Estimadores significantes(por cada unidad de estas variables, sube en * unidades la variable dependiente:  
-GRE = 0.078876*    
-CGPA = 0.395942*  
-LOR = 0.055364*  
-RESEARCH = 0.025020*  
-TOEFL = 0.074931*

R2 = 0.7953 
Las variables presentes en este modelo representan ~ 80% de la variabilidad de ADMIT, la variable dependiente.  

El R2 en este modelo mejoró.

```{r}
names(admissions)
model_2 <- lm(ADMIT ~ GRE + TOEFL + CGPA + UNI + SOP + LOR + RESEARCH,data=train_set)

model_2

summary(model_2)

```
####No hay evidencia de multicolinealidad

```{r}
vif(model_2)
```


####Estudiemos la posibilidad de eliminar variables que no aporten a nuestro modelo. Realizaremos un test anova en distintos escenario con distintos modelos.  

#####Al hacer un test anova con modelos sin las variables TEOFL,SOP, ni UNIVERISTY RATING(UNI), vemos que el test anova nos retorna un valor significante, que significa que esas tres variable juntas SI aportan a nuestro modelo. Sin embargo, el mismo test con el modelo sin la variable SOP, nos dice que esta variable realmente no nos contribuye en nada. Mas abajo vemos que incluso al eliminar la variable SOP, nuestro R2 mejora.
```{r}

model_drop_uni_sop_teo <- lm(ADMIT ~ GRE + CGPA + LOR + RESEARCH,data = train_set)

model_drop_uni <- lm(ADMIT ~ GRE + TOEFL + CGPA  + SOP + LOR + RESEARCH,data=train_set)

model_drop_sop <- lm(ADMIT ~ GRE + TOEFL + CGPA + UNI + LOR + RESEARCH,data=train_set)

model_drop_teo <- lm(ADMIT ~ GRE  + CGPA + UNI + SOP + LOR + RESEARCH,data=train_set)

model_drop_uni_teo <- lm(ADMIT ~ GRE + CGPA + SOP + LOR + RESEARCH,data=train_set)

anova(model_drop_uni_sop_teo,model_2)
#TEOFL,UNI and SOP agregan valor significante al modelo, mantenerlos.

anova(model_drop_uni,model_2)#p-value insignificante 0.2526

anova(model_drop_sop,model_2)#p-value insignificante 0.5002

anova(model_drop_teo,model_2)#p-value significante 0.0227

anova(model_drop_uni_teo,model_2)# p-value significante, eliminar uni y teo afectaria al modelo

#Drop la variable SOP
```
####Modelo 2 sin SOP tiene un R2 = 0.7957, un poco mejor que antes.
```{r}
summary(model_drop_sop)

model_2_final <- model_drop_sop
```
####RMSE test del modelo 2 en nuestro set de validacion
```{r}

val_set$model_2 <- predict(model_2_final,newdata=val_set)

(RMSE_model_2 <- sqrt(mean((admit - val_set$model_2)^2)))
#RMSE = 0.0610645
#R2 = 0.7957
```

####El segundo modelo nos dio un RMSE menor al modelo 1, como tambien un R2 mejor.  
####El segundo modelo entonces es mejor con un RMSE de 0.0610645 y un R2 de 0.7957.

####Apliquemos el modelo entonces a nuestra test data, que en este analisis representaria data nunca antes vista y nos daria una idea de como se comportaria en "el mundo real":

```{r}
test_set$model_2 <- predict(model_2_final,newdata=test_set)

(rmse_model_2_test <- sqrt(mean((test_set$ADMIT - test_set$model_2)^2)))

```

####Un RMSE de 0.04547105, impecable! 

```{r}
ggplot(test_set,aes(x = model_2, y = ADMIT))+
  geom_point()+
  geom_smooth(method = 'lm', se = F)
```

















